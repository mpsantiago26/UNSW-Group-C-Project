{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0013bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script Name: Combination of Temperature and Energy Demand\n",
    "# Author: Rahul Kumar\n",
    "# Date: 4/3/22\n",
    "# Description: The purpose of the script is to combine the temperature and energy demand data into a unified dataset that \n",
    "# can be used to work with\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This actually sets the pandas display to show all rows and columns \n",
    "# when you are showing a dataframe, without skipping the center\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1285f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../../UNSW-PROJECT-DATA/H06-2021/' # If you want to run the code, change the file path to where you store the files. This reference\n",
    "                                # is to where I store the files outside the github clone\n",
    "    \n",
    "outpath = '../../UNSW-PROJECT-DATA/' #I store it on my comp and the copy the file to the server\n",
    "# filename = 'totaldemand_nsw'\n",
    "ext = '.csv'\n",
    "\n",
    "states = ['nsw','qld','sa','vic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e6e0a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 'temprature', 'totaldemand', 'forecastdemand'\n",
    "\n",
    "filename = 'temprature' #<-correct your NSW temperature filename to temprature\n",
    "temp = pd.DataFrame(columns=['STATE','LOCATION','DATETIME','TEMPERATURE'])\n",
    "\n",
    "for state in states:\n",
    "    df = pd.read_csv(filepath+filename+'_'+state+ext)\n",
    "    df['STATE'] = state.upper()\n",
    "    df['DATETIME'] = pd.to_datetime(df['DATETIME'])\n",
    "    temp = pd.concat([temp,df], ignore_index=True)\n",
    "    \n",
    "temp = temp[['STATE','LOCATION','DATETIME','TEMPERATURE']]\n",
    "temp.to_csv(outpath+filename+ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "890d662c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'totaldemand'\n",
    "demand = pd.DataFrame(columns=['STATE','DATETIME','TOTALDEMAND','REGIONID'])\n",
    "\n",
    "for state in states:\n",
    "    df = pd.read_csv(filepath+filename+'_'+state+ext)\n",
    "    df['STATE'] = state.upper()\n",
    "    df['DATETIME'] = pd.to_datetime(df['DATETIME'])\n",
    "    demand = pd.concat([demand,df], ignore_index=True)\n",
    "\n",
    "demand = demand[['STATE','DATETIME','TOTALDEMAND']]\n",
    "demand.to_csv(outpath+filename+ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07cc3548",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fd_nsw = fd_nsw[['FORECASTDEMAND','DATETIME']]\n",
    "# fd_nsw = fd_nsw.groupby('DATETIME').mean().reset_index()\n",
    "\n",
    "filename = 'forecastdemand'\n",
    "fdemand = pd.DataFrame(columns=['STATE','FORECASTDEMAND','DATETIME'])\n",
    "\n",
    "for state in states:\n",
    "    df = pd.read_csv(filepath+filename+'_'+state+ext)\n",
    "    df = df.groupby('DATETIME').mean().reset_index()\n",
    "    df['STATE'] = state.upper()\n",
    "    df['DATETIME'] = pd.to_datetime(df['DATETIME'])\n",
    "    df = df[['STATE','FORECASTDEMAND','DATETIME']]\n",
    "    fdemand = pd.concat([fdemand,df], ignore_index=True)\n",
    "    \n",
    "fdemand.to_csv(outpath+'mean_'+filename+ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bb60061",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Knowing that Total Demand has the most rows, we will merge on that\n",
    "# DF STATE Date rows - 418,012\n",
    "# Temp STATE Date rows - 778,177\n",
    "# TD STATE Date rows - 786,051\n",
    "\n",
    "filename = 'combined'\n",
    "combined = demand.merge(temp, left_on=['STATE','DATETIME'], right_on = ['STATE','DATETIME'],how = 'outer')\n",
    "combined_fdavg = combined.merge(fdemand, left_on=['STATE','DATETIME'], right_on = ['STATE','DATETIME'],how = 'outer')\n",
    "\n",
    "# Based on the Climate Glossary - http://www.bom.gov.au/climate/glossary/seasons.shtml the seasons are broken down as\n",
    "# follows: 9,10,11 are Spring, 12,1,2 are Summer, 3,4,5 are Autumn and 6,7,8 are Winter\n",
    "\n",
    "def Season(item):\n",
    "    if item == 12 or item == 1 or item == 2:\n",
    "        return 'Summer'\n",
    "    elif item == 3 or item == 4 or item == 5:\n",
    "        return 'Autumn'\n",
    "    elif item == 6 or item == 7 or item == 8:\n",
    "        return 'Winter'\n",
    "    else:\n",
    "        return 'Spring'\n",
    "    \n",
    "\n",
    "combined['DATETIME'] = pd.to_datetime(combined['DATETIME'])\n",
    "combined['Weekday'] = combined['DATETIME'].dt.day_name()\n",
    "combined['Quarter'] = combined['DATETIME'].dt.quarter\n",
    "combined['Month'] = combined['DATETIME'].dt.month\n",
    "combined['Season'] = combined['Month'].apply(Season)\n",
    "\n",
    "combined_fdavg['DATETIME'] = pd.to_datetime(combined_fdavg['DATETIME'])\n",
    "combined_fdavg['Weekday'] = combined_fdavg['DATETIME'].dt.day_name()\n",
    "combined_fdavg['Quarter'] = combined_fdavg['DATETIME'].dt.quarter\n",
    "combined_fdavg['Month'] = combined_fdavg['DATETIME'].dt.month\n",
    "combined_fdavg['Season'] = combined_fdavg['Month'].apply(Season)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05c454a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://meteostat.net/en/blog/obtain-weather-data-any-location-python\n",
    "\n",
    "# Can be potentially used to fill any missing temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0edd6ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sunset sunrise\n",
    "\n",
    "sunrise = pd.DataFrame(columns=['STATE','SUNRISE','SUNSET'])\n",
    "\n",
    "def hour_split(number):\n",
    "    number = str(number)\n",
    "    hour = number[:-2]\n",
    "    return (hour)\n",
    "\n",
    "def min_split(number):\n",
    "    number = str(number)\n",
    "    minutes = number[-2:]\n",
    "    return int(minutes)\n",
    "\n",
    "filepath2 = '../../UNSW-PROJECT-DATA/Sunrise Sunset Data/'\n",
    "STATE2 = ['NSW', 'QLD', 'SA', 'VIC']\n",
    "filename = 'times of sunrise and sunset annual results '\n",
    "years = ['2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021']\n",
    "\n",
    "for state in STATE2:\n",
    "    for year in years:\n",
    "        df = pd.read_csv(filepath2+state+'/'+filename+year+ext)\n",
    "        df['year'] = int(year)\n",
    "        df['risehr'] = df['rise'].apply(hour_split)\n",
    "        df['risemn'] = df['rise'].apply(min_split)\n",
    "        df['sethr'] = df['set'].apply(hour_split)\n",
    "        df['setmn'] = df['set'].apply(min_split)\n",
    "        df['SUNRISE']= pd.to_datetime(dict(year=df.year, month=df.month, day = df.day, hour = df.risehr, minute = df.risemn))\n",
    "        df['SUNSET']= pd.to_datetime(dict(year=df.year, month=df.month, day = df.day, hour = df.sethr, minute = df.setmn))\n",
    "        df = df[['SUNRISE','SUNSET']]\n",
    "        df['STATE'] = state\n",
    "        sunrise = pd.concat([sunrise,df], ignore_index=True)\n",
    "\n",
    "sunrise.to_csv('../data/'+'sunrise_sunset_combined'+ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa8e70c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['Day'] = combined['DATETIME'].dt.day\n",
    "combined['Year'] = combined['DATETIME'].dt.year\n",
    "\n",
    "combined_fdavg['Day'] = combined_fdavg['DATETIME'].dt.day\n",
    "combined_fdavg['Year'] = combined_fdavg['DATETIME'].dt.year\n",
    "\n",
    "sunrise['Day'] = sunrise['SUNRISE'].dt.day\n",
    "sunrise['Year'] = sunrise['SUNRISE'].dt.year\n",
    "sunrise['Month'] = sunrise['SUNRISE'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbeb6b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.merge(sunrise, left_on=['Day','Month','Year','STATE'], right_on = ['Day','Month','Year','STATE'],how = 'inner')\n",
    "combined_fdavg = combined_fdavg.merge(sunrise, left_on=['Day','Month','Year','STATE'], right_on = ['Day','Month','Year','STATE'],how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fc996ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (combined['DATETIME'] >= combined['SUNRISE']) & (combined['DATETIME'] <= combined['SUNSET']),\n",
    "    (combined['DATETIME'] > combined['SUNSET'])]\n",
    "choices = ['Day', 'Night']\n",
    "combined['DAYTYPE'] = np.select(conditions, choices, default='Night')\n",
    "\n",
    "conditions = [\n",
    "    (combined_fdavg['DATETIME'] >= combined_fdavg['SUNRISE']) & (combined_fdavg['DATETIME'] <= combined_fdavg['SUNSET']),\n",
    "    (combined_fdavg['DATETIME'] > combined_fdavg['SUNSET'])]\n",
    "choices = ['Day', 'Night']\n",
    "combined_fdavg['DAYTYPE'] = np.select(conditions, choices, default='Night')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "532a9cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'combined'\n",
    "combined.to_csv(outpath+filename+ext)\n",
    "combined_fdavg.to_csv(outpath+filename+'_fd_Avg'+ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2ccc799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATE              0\n",
       "DATETIME           0\n",
       "TOTALDEMAND    56756\n",
       "LOCATION       64643\n",
       "TEMPERATURE    64643\n",
       "Weekday            0\n",
       "Quarter            0\n",
       "Month              0\n",
       "Season             0\n",
       "Day                0\n",
       "Year               0\n",
       "SUNRISE            0\n",
       "SUNSET             0\n",
       "DAYTYPE            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dont remove\n",
    "combined.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc120fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATE                  0\n",
       "DATETIME               0\n",
       "TOTALDEMAND        58220\n",
       "LOCATION           66107\n",
       "TEMPERATURE        66107\n",
       "FORECASTDEMAND    426259\n",
       "Weekday                0\n",
       "Quarter                0\n",
       "Month                  0\n",
       "Season                 0\n",
       "Day                    0\n",
       "Year                   0\n",
       "SUNRISE                0\n",
       "SUNSET                 0\n",
       "DAYTYPE                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_fdavg.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a1d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
